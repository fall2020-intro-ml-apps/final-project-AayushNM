{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv ('application_train.csv')\n",
    "df_test = pd.read_csv ('application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encoding of the categorical columns\n",
    "label_enc = [\"NAME_CONTRACT_TYPE\", \"CODE_GENDER\", \n",
    "            \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\", \n",
    "            \"NAME_TYPE_SUITE\", \n",
    "            \"NAME_INCOME_TYPE\",\n",
    "            \"NAME_EDUCATION_TYPE\",\n",
    "            \"NAME_FAMILY_STATUS\",\n",
    "            \"NAME_HOUSING_TYPE\", \"WEEKDAY_APPR_PROCESS_START\", \n",
    "            \"ORGANIZATION_TYPE\"]\n",
    "\n",
    "#Now droping columns which can not be label encoded or features which don't posses any significance to the predicted \n",
    "#value \n",
    "d_columns = ['OCCUPATION_TYPE', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE']  \n",
    "df_train = df_train.drop(columns = d_columns[0:5])\n",
    "df_test = df_test.drop(columns = d_columns[0:5])\n",
    "\n",
    "for col in label_enc:\n",
    "    label = preprocessing.LabelEncoder()\n",
    "    label.fit(list(df_train[col].values.astype('str')) + list(df_test[col].values.astype('str')))\n",
    "    df_train[col] = label.transform(list(df_train[col].values.astype('str')))\n",
    "    df_test[col] = label.transform(list(df_test[col].values.astype('str')))\n",
    "\n",
    "## All models should be run independently from the indicated start sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Model Implementation\n",
    "\n",
    "#Dropping columns with null values\n",
    "df_train=df_train[df_train.columns[~df_train.isnull().any()]]\n",
    "df_test=df_test[df_test.columns[~df_test.isnull().any()]]\n",
    "df_test.drop(['DAYS_LAST_PHONE_CHANGE',  'CNT_FAM_MEMBERS', 'AMT_GOODS_PRICE'], axis = 1, inplace = True) \n",
    "\n",
    "#Removing the 'Traget' column from the main training dataset and assigning variable y with the target\n",
    "X=df_train.loc[:, df_train.columns != 'TARGET']\n",
    "y=df_train.loc[:, df_train.columns == 'TARGET']\n",
    "\n",
    "#Performing test-train split with a 20:80 ratio\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                                                    train_size=0.80,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=99)\n",
    "#Applying Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_X, train_y)\n",
    "logreg_model_score = logreg.score( train_X, train_y)\n",
    "logreg_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting Target probabilities and Calculating the ROC AUC score\n",
    "logreg_pred=logreg.predict_proba(df_test)[:, 1]\n",
    "logreg_pred_log_proba = logreg.predict_log_proba(test_X)[:,1]\n",
    "logreg_model_ROC = roc_auc_score(test_y, logreg_pred_log_proba)\n",
    "logreg_model_ROC\n",
    "#ROC=0.5888641171603671"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Submission file for submission\n",
    "submit = df_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = logreg_pred\n",
    "submit.to_csv('logreg.csv', index = False)\n",
    "#Score=0.59837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model Implementation\n",
    "randforest = RandomForestClassifier(random_state = 99,n_jobs = -1)\n",
    "X=df_train.loc[:, df_train.columns != 'TARGET']\n",
    "y=df_train.loc[:, df_train.columns == 'TARGET']\n",
    "\n",
    "#Performing test-train split 20:80\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                                                    train_size=0.80,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the Model\n",
    "randforest.fit(train_X, train_y)\n",
    "\n",
    "#Calculating the accuracy score\n",
    "RandForest_Model = randforest.score( train_X, train_y)\n",
    "RandForest_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating ROC AUC Score\n",
    "random_pred=randforest.predict_proba(df_test)[:, 1]\n",
    "random_pred_log_proba = randforest.predict_proba(test_X)[:,1]\n",
    "randforest_model_ROC = roc_auc_score(test_y, random_pred_log_proba)\n",
    "randforest_model_ROC\n",
    "#ROC=0.6345390792685979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Submission file\n",
    "submit = df_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = random_pred\n",
    "submit.to_csv('randforest.csv', index = False)\n",
    "#Score=0.63612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBM implimentation\n",
    "\n",
    "#Removing the 'Traget' column from the main training dataset and assigning variable y with the target\n",
    "X=df_train.loc[:, df_train.columns != 'TARGET']\n",
    "y=df_train.loc[:, df_train.columns == 'TARGET']\n",
    "\n",
    "#Performing test-train split with a 20:80 ratio\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                                                    train_size=0.80,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=99)\n",
    "\n",
    "#Listing all the Features and storing them in the variable 'features'\n",
    "features= list(df_test.columns)\n",
    "\n",
    "#Creating an emplty column to contain the predicted values\n",
    "test_preds = np.zeros(df_test.shape[0])\n",
    "\n",
    "#Setting up KFold Cross Validation\n",
    "kfold = KFold(shuffle = True, random_state = 99)\n",
    "        \n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=4000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=30,\n",
    "    colsample_bytree=.8,\n",
    "    subsample=.9,\n",
    "    max_depth=7,\n",
    "    reg_alpha=.1,\n",
    "    reg_lambda=.1,\n",
    "    min_split_gain=.01,\n",
    "    min_child_weight=2,\n",
    "    silent=-1,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "#Implementing LightGBM on the Dataset with early stopping set to 100\n",
    "lgbm.fit(train_X, train_y, \n",
    "        eval_set= [(train_X, train_y), (test_X, test_y)], \n",
    "        eval_metric='auc', verbose=100, early_stopping_rounds=100\n",
    "        )\n",
    "\n",
    "#Implementing KFold Cross Validation\n",
    "for n, (train_i, test_i) in enumerate(kfold.split(df_train)): \n",
    "    test_preds += lgbm.predict_proba(df_test[features], num_iteration=lgbm.best_iteration_)[:,1] / kfold.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the Accuracy score\n",
    "accuracy_score(test_y, lgbm.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance Calculation\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df[\"feature\"] = features\n",
    "feature_importance_df[\"importance percent\"] = lgbm.feature_importances_\n",
    "feature_importance_df['importance percent']= (feature_importance_df['importance percent']/100)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating ROC AUC Score\n",
    "lgbm_pred_log_proba = lgbm.predict_proba(test_X)[:,1]\n",
    "lgbm_model_ROC = roc_auc_score(test_y, lgbm_pred_log_proba)\n",
    "lgbm_model_ROC\n",
    "#ROC=0.6835767676225897\n",
    "#ROC=0.7625142284859512 #without droping null columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the file for submission\n",
    "submit = pd.DataFrame()\n",
    "submit['SK_ID_CURR']= df_test['SK_ID_CURR']\n",
    "submit['TARGET'] = test_preds\n",
    "submit.sum(axis = 0, skipna = True)\n",
    "submit.to_csv('lgbm.csv', index = False)\n",
    "#Score=0.74687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost Model Implementation\n",
    "adamodel = AdaBoostClassifier(random_state=99)\n",
    "X=df_train.loc[:, df_train.columns != 'TARGET']\n",
    "y=df_train.loc[:, df_train.columns == 'TARGET']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                                                    train_size=0.80,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=99)\n",
    "adamodel.fit(train_X, train_y)\n",
    "ada_score=adamodel.score(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Accuracy Score\n",
    "ada_score=adamodel.score(train_X, train_y)\n",
    "ada_pred=adamodel.predict_proba(df_test)[:, 1]\n",
    "ada_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Feature importance\n",
    "features= list(df_test.columns)\n",
    "ada_feature_importance_df = pd.DataFrame()\n",
    "ada_feature_importance_df[\"feature\"] = features\n",
    "ada_feature_importance_df[\"importance percent\"] = adamodel.feature_importances_\n",
    "ada_feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Calculation\n",
    "ada_pred = adamodel.predict_log_proba(test_X)[:,1]\n",
    "ada_model_ROC = roc_auc_score(test_y, ada_pred)\n",
    "ada_model_ROC\n",
    "#ROC=0.6695558382404692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Submission\n",
    "submit = df_test[['SK_ID_CURR']]\n",
    "submit['TARGET'] = ada_pred\n",
    "submit.to_csv('adaBoost.csv', index = False)\n",
    "#Score= 0.66936"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
